{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import hashlib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    hdfs dfs -mkdir -p assign2\\n    hdfs dfs -put <path>/ratings.csv assign2/\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    hdfs dfs -mkdir -p assign2\n",
    "    hdfs dfs -put <path>/ratings.csv assign2/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master='local', appName=\"Assignment2_E2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_data = sc.textFile(\"assign2/ratings_small.csv\")\n",
    "header = ratings_data.first() #extract header\n",
    "ratings_data = ratings_data.filter(lambda line: line != header)   #filter out header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ratings_data.map(lambda line: re.split(',', line.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ratings by user\n",
    "by_users = data.map(lambda elem: (elem[0],(elem[1], elem[2]))).groupByKey().mapValues(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = by_users.count()\n",
    "num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get ratings by movies\n",
    "by_movie = data.map(lambda elem: (elem[1],(elem[0], elem[2]))).groupByKey().mapValues(list)\n",
    "num_movies = by_movie.count()\n",
    "num_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Create a ratings matrix \n",
    "    keys -> moviesID\n",
    "    values -> list of ratings => indexes: usersID\n",
    "'''\n",
    "def get_matrix(by_movie, num_users):\n",
    "    matrix = {}\n",
    "    for movieID,value in by_movie.collect():\n",
    "        users_vector = [0 for j in range(num_users)]\n",
    "        for userID,rating in value:\n",
    "            users_vector[int(userID)-1] = float(rating)\n",
    "            #index_movieID = movies_dict[movieID]\n",
    "            #matrix[index_movieID][int(userID)-1] = float(rating)\n",
    "        matrix[movieID] = users_vector   \n",
    "        \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix = get_matrix(by_movie, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Calculate similarity between two vectors\n",
    "'''\n",
    "def calc_similarity(vector1, vector2):\n",
    "    mean_vector1 = np.mean([value for value in vector1 if value!=0])\n",
    "    v1 = [value-mean_vector1 for value in vector1]\n",
    "    \n",
    "    mean_vector2 = np.mean([value for value in vector2 if value!=0])\n",
    "    v2 = [value-mean_vector2 for value in vector2]\n",
    "\n",
    "    sim = np.dot(v1, v2) / (np.sqrt(np.dot(v1, v1) * np.dot(v2, v2))) #Cosine    \n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "      5 Most similar items (neighbors) to a given movie\n",
    "'''\n",
    "def get_similar_movies(ratings_matrix, by_users, movie, selected_user):\n",
    "    similar_movs = []\n",
    "    # Movies user has seen\n",
    "    users_dict = by_users.collect()\n",
    "    for user, ratings in users_dict:\n",
    "        user_idx = int(user)-1\n",
    "        if user_idx == selected_user:\n",
    "            # Iterate movies\n",
    "            for movie_2 in ratings_matrix:\n",
    "                # Only watched movies\n",
    "                if movie != movie_2 and ratings_matrix[movie_2][selected_user] != 0:\n",
    "                    sim = calc_similarity(ratings_matrix[movie], ratings_matrix[movie_2])\n",
    "                    similar_movs.append((movie_2, ratings_matrix[movie_2][selected_user], sim))\n",
    "                        \n",
    "    similar_movs.sort(key=lambda y: y[2], reverse=True)\n",
    "    # Only 5 more similar\n",
    "    return similar_movs[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Estimate a rating based on similar_movies\n",
    "'''\n",
    "def estimate_rating(similar_movs):\n",
    "    rating_predicted = 0\n",
    "    similarity_sum = 0\n",
    "    for m1, rating, sim in similar_movs:\n",
    "        similarity_sum += sim\n",
    "        rating_predicted += rating*sim\n",
    "    \n",
    "    return round(rating_predicted / similarity_sum, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of similar movies:  0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Test \n",
    "movie = \"25\"\n",
    "user = 1\n",
    "\n",
    "sim_movies = get_similar_movies(ratings_matrix, by_users,movie, user) # Neighbor selection\n",
    "print(\"Number of similar movies: \",len(sim_movies))\n",
    "print(sim_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimate rating: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43mestimate_rating\u001b[49m\u001b[43m(\u001b[49m\u001b[43msim_movies\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mestimate_rating\u001b[0;34m(similar_movs)\u001b[0m\n\u001b[1;32m      8\u001b[0m     similarity_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sim\n\u001b[1;32m      9\u001b[0m     rating_predicted \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m rating\u001b[38;5;241m*\u001b[39msim\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mround\u001b[39m(\u001b[43mrating_predicted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msimilarity_sum\u001b[49m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "print(\"Estimate rating: \",estimate_rating(sim_movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Get ratings predictions\n",
    "'''\n",
    "def model_evaluation(data_test, total_matrix):\n",
    "    real_ratings = []\n",
    "    predicted_ratings = []\n",
    "    for line in data_test:\n",
    "            user, movie, rating, _ = line\n",
    "            user = int(user)-1\n",
    "            real_ratings.append(float(rating))\n",
    "            sm = get_similar_movies(total_matrix, by_users, movie, user) # Neighbor selection\n",
    "            predicted_ratings.append(estimate_rating(sm)) # Estimated rating\n",
    "\n",
    "    return real_ratings, predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get 10% of the data to evaluate\n",
    "evaluation_size = round(data.count() * 0.1)\n",
    "evaluation_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9363/2218074375.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim = np.dot(v1, v2) / (np.sqrt(np.dot(v1, v1) * np.dot(v2, v2))) #Cosine\n"
     ]
    }
   ],
   "source": [
    "real_ratings, predicted_ratings = model_evaluation(data.take(evaluation_size), ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_ratings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Calculate RMSE\n",
    "'''\n",
    "def calc_rmse(real_ratings, predicted_ratings):\n",
    "    quo = sum([ (predicted_ratings[i]-real_ratings[i])**2 for i in range(len(real_ratings))])\n",
    "    den = len(predicted_ratings)\n",
    "    return math.sqrt( quo / den )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Calculate Presision at top 10\n",
    "'''\n",
    "def calc_precision(real_ratings, predicted_ratings):\n",
    "    quo = sum([1 for i in range(len(real_ratings)) if (round(real_ratings[i])==round(predicted_ratings[i]))])\n",
    "    den = len(predicted_ratings)\n",
    "    precision = quo / den\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value: nan\n"
     ]
    }
   ],
   "source": [
    "rmse = calc_rmse(real_ratings, predicted_ratings)\n",
    "print(\"RMSE value: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m precision_10 \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_precision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_ratings\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_ratings\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision at top 10 value: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(precision_10))\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mcalc_precision\u001b[0;34m(real_ratings, predicted_ratings)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_precision\u001b[39m(real_ratings, predicted_ratings):\n\u001b[0;32m----> 5\u001b[0m     quo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(real_ratings)) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mround\u001b[39m(real_ratings[i])\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mround\u001b[39m(predicted_ratings[i]))])\n\u001b[1;32m      6\u001b[0m     den \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(predicted_ratings)\n\u001b[1;32m      7\u001b[0m     precision \u001b[38;5;241m=\u001b[39m quo \u001b[38;5;241m/\u001b[39m den\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_precision\u001b[39m(real_ratings, predicted_ratings):\n\u001b[0;32m----> 5\u001b[0m     quo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(real_ratings)) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mround\u001b[39m(real_ratings[i])\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpredicted_ratings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)])\n\u001b[1;32m      6\u001b[0m     den \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(predicted_ratings)\n\u001b[1;32m      7\u001b[0m     precision \u001b[38;5;241m=\u001b[39m quo \u001b[38;5;241m/\u001b[39m den\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "precision_10 = calc_precision(real_ratings[:10], predicted_ratings[:10])\n",
    "print(\"Precision at top 10 value: {}\".format(precision_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [(\"Precision_10\", precision_10), (\"RMSE\", rmse)]\n",
    "result_rdd = sc.parallelize(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_rdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m format_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m \u001b[43mresult_rdd\u001b[49m\u001b[38;5;241m.\u001b[39msaveAsTextFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massign2/results/ex2_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(evaluation_size), format_time))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result_rdd' is not defined"
     ]
    }
   ],
   "source": [
    "format_time = str(datetime.now().strftime(\"%Y-%m-%dT%H_%M_%S\"))\n",
    "result_rdd.saveAsTextFile(\"{0}_{1}\".format(\"assign2/results/ex2_\"+str(evaluation_size), format_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
